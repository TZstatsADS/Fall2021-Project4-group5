{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness-Aware Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPAS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import math\n",
    "\n",
    "fp = '../data/compas-scores-two-years.csv'\n",
    "compas_df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_compas_dataset(compas_df): \n",
    "    #Drop Missing values and subset on columns needed\n",
    "    compas_df.dropna()\n",
    "    compas_subset = compas_df[[\"sex\",\"age\",\"age_cat\",\"race\",\"priors_count\",\"c_charge_degree\",\"c_jail_in\", \"c_jail_out\",'two_year_recid']]\n",
    "    compas_subset[\"two_year_recid\"] = compas_subset[\"two_year_recid\"].apply(lambda x: -1 if x==0 else 1)\n",
    "    \n",
    "    #Only select Caucasian/African American, encode to 0/1\n",
    "    compas_subset = compas_subset[(compas_subset[\"race\"]=='Caucasian') |(compas_subset[\"race\"]=='African-American') ]\n",
    "    compas_subset[\"race_cat\"] = compas_subset[\"race\"].apply(lambda x: 1 if x == \"Caucasian\" else 0)\n",
    "    compas_subset = compas_subset.drop(columns = \"race\")\n",
    "    \n",
    "    #Encode gender to 0/1\n",
    "    compas_subset[\"gender_cat\"] = compas_subset[\"sex\"].apply(lambda x: 1 if x == \"Female\" else 0)\n",
    "    compas_subset = compas_subset.drop(columns = \"sex\")\n",
    "    \n",
    "    #Encode charge degree to 0/1\n",
    "    compas_subset[\"charge_cat\"] = compas_subset[\"c_charge_degree\"].apply(lambda x: 1 if x == \"F\" else 0)\n",
    "    compas_subset = compas_subset.drop(columns = \"c_charge_degree\")\n",
    "    \n",
    "    #Calculate length of stay from jail out - jail in \n",
    "    compas_subset[\"length_stay\"] = pd.to_datetime(compas_subset[\"c_jail_out\"]) - pd.to_datetime(compas_subset['c_jail_in'])\n",
    "    compas_subset[\"length_stay\"] = compas_subset[\"length_stay\"].apply(lambda x: x.days)\n",
    "    compas_subset = compas_subset.drop(columns = [\"c_jail_in\",\"c_jail_out\"])\n",
    "    compas_subset['length_stay'] = compas_subset[\"length_stay\"].apply(lambda x: 0 if x <= 7 else x)\n",
    "    compas_subset['length_stay'] = compas_subset[\"length_stay\"].apply(lambda x: 1 if 7< x <= 90 else x)\n",
    "    compas_subset['length_stay'] = compas_subset[\"length_stay\"].apply(lambda x: 2 if x > 90 else x)\n",
    "    \n",
    "    #Categorize priors count into 3 categories \n",
    "    compas_subset[\"priors_count\"] = compas_subset[\"priors_count\"].apply(lambda x: 0 if x==0 else x)\n",
    "    compas_subset[\"priors_count\"] = compas_subset[\"priors_count\"].apply(lambda x: 1 if (1<=x<=3) else x)\n",
    "    compas_subset[\"priors_count\"] = compas_subset[\"priors_count\"].apply(lambda x: 2 if x>3 else x)\n",
    "    \n",
    "    # Include age as categorical variable \n",
    "    compas_subset = compas_subset.drop(columns = [\"age_cat\"])\n",
    "    \n",
    "    compas_subset = compas_subset.dropna()\n",
    "    y_label = compas_subset[\"two_year_recid\"]\n",
    "    protected_attribute = compas_subset[\"race_cat\"]\n",
    "    df = compas_subset.drop(columns=[\"two_year_recid\",\"race_cat\"])\n",
    "\n",
    "    y_label, protected_attr, df = shuffle(y_label, protected_attribute, df, random_state = 0)\n",
    "\n",
    "    return y_label.to_numpy(), protected_attr.to_numpy(), df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nikhil/anaconda3/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "y_label, protected_attr, X =  process_compas_dataset(compas_df)\n",
    "\n",
    "train_index = int(len(X)*6./7.)\n",
    "x_train, y_train, race_train = X[:train_index], y_label[:train_index], protected_attr[:train_index]\n",
    "x_test, y_test, race_test = X[train_index:], y_label[train_index:],protected_attr[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we implement the routines described in \"Information Theoretic Measures for Fairness-aware Feature Selection.\" On the training data, we calculate Shapley coefficients for each of our features capturing effects on both accuracy and discrimation on our protected group (i.e. race)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell contains utility functions called in the proceeding cells.\"\"\"\n",
    "\n",
    "def get_uniq_vals_in_arr(arr):\n",
    "    \"\"\"Returns unique values in array.\n",
    "    \n",
    "    :param arr (np.array) n * m matrix\n",
    "    :return (list) uniq_vals[i] contains unique values of ith column in arr\n",
    "    \"\"\"\n",
    "    uniq_vals = []\n",
    "    for id_col in range(arr.shape[1]):\n",
    "        uniq_vals.append(np.unique(arr[:, id_col]).tolist())\n",
    "    return uniq_vals\n",
    "\n",
    "\n",
    "def powerset(seq):\n",
    "    \"\"\"\n",
    "    Returns all the subsets of this set. This is a generator.\n",
    "    \"\"\"\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell contains code for all the routines needed to calculate the Shapley coefficients.\"\"\"\n",
    "\n",
    "def get_info_coef(left, right):\n",
    "    # Both arrays NEED same number of rows\n",
    "    assert left.shape[0] == right.shape[0]\n",
    "    num_rows = left.shape[0]\n",
    "    num_left_cols = left.shape[1]\n",
    "        \n",
    "    concat_mat = np.concatenate((left, right), axis=1)\n",
    "    concat_uniq_vals = get_uniq_vals_in_arr(concat_mat)\n",
    "    concat_combos = list(itertools.product(*concat_uniq_vals))\n",
    "    p_sum = 0\n",
    "    for vec in concat_combos:\n",
    "        p_r1_r2 = len(np.where((concat_mat == vec).all(axis=1))[0]) / num_rows\n",
    "        p_r1 = len(np.where((left == vec[:num_left_cols]).all(axis=1))[0]) / num_rows\n",
    "        p_r2 = len(np.where((right == vec[num_left_cols:]).all(axis=1))[0]) / num_rows\n",
    "        \n",
    "        if p_r1_r2 == 0 or p_r1 == 0 or p_r2 == 0:\n",
    "            p_iter = 0\n",
    "        else:\n",
    "            p_iter = p_r1_r2 * np.log(p_r1_r2 / p_r1) / p_r1\n",
    "        p_sum += np.abs(p_iter)\n",
    "    return p_sum\n",
    "\n",
    "\n",
    "def get_conditional_info_coef(left, right, conditional): \n",
    "    assert (left.shape[0] == right.shape[0]) and (left.shape[0] == conditional.shape[0])\n",
    "    num_rows = left.shape[0]\n",
    "    num_left_cols = left.shape[1]\n",
    "    num_right_cols = right.shape[1]\n",
    "\n",
    "    right_concat_mat = np.concatenate((right, conditional), axis=1)    \n",
    "    concat_mat = np.concatenate((left, right_concat_mat), axis=1)\n",
    "    concat_uniq_vals = get_uniq_vals_in_arr(concat_mat)\n",
    "    concat_combos = list(itertools.product(*concat_uniq_vals))\n",
    "    p_sum = 0\n",
    "    for vec in concat_combos:\n",
    "        p_r1_r2 = len(np.where((concat_mat == vec).all(axis=1))[0]) / num_rows\n",
    "        p_r1 = len(np.where((left == vec[:num_left_cols]).all(axis=1))[0]) / num_rows\n",
    "        p_r2 = len(np.where((concat_mat[:, num_left_cols: -num_right_cols] == vec[num_left_cols: -num_right_cols]).all(axis=1))[0]) / num_rows\n",
    "        \n",
    "        try:\n",
    "            p_r1_given_r3 = len(np.where((concat_mat[:, :num_left_cols] == vec[:num_left_cols]).all(axis=1) & (concat_mat[:, -num_right_cols:] == vec[-num_right_cols:]).all(axis=1))[0]) / len(np.where((concat_mat[:, -num_right_cols:] == vec[-num_right_cols:]).all(axis=1))[0])\n",
    "        except ZeroDivisionError:\n",
    "            p_r1_given_r3 = 0\n",
    "        \n",
    "        if p_r1_r2 == 0 or p_r1 == 0 or p_r2 == 0 or p_r1_given_r3 == 0:\n",
    "            p_iter = 0\n",
    "        else:\n",
    "            p_iter = p_r1_r2 * np.log(p_r1_r2 / p_r2) / p_r1_given_r3\n",
    "        p_sum += np.abs(p_iter)\n",
    "    return p_sum\n",
    "\n",
    "\n",
    "def get_acc_coef(y, x_s, x_s_c, protected_attr):\n",
    "    conditional = np.concatenate((x_s_c, protected_attr), axis=1)\n",
    "    return get_conditional_info_coef(y, x_s, conditional)\n",
    "\n",
    "\n",
    "def get_disc_coef(y, x_s, protected_attr):\n",
    "    x_s_a = np.concatenate((x_s, protected_attr), axis=1)\n",
    "    return get_info_coef(y, x_s_a) * get_info_coef(x_s, protected_attr) * get_conditional_info_coef(x_s, protected_attr, y)\n",
    "\n",
    "\n",
    "def get_shapley_acc_i(y, x, protected_attr, i):\n",
    "    \"\"\"Returns Shapley coeffecient of ith feature in x.\"\"\"\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    lst_idx = list(range(num_features))\n",
    "    lst_idx.pop(i)\n",
    "    power_set = [x for x in powerset(lst_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley = 0\n",
    "    for set_idx in power_set:\n",
    "        coef = math.factorial(len(set_idx)) * math.factorial(num_features - len(set_idx) - 1) / math.factorial(num_features)\n",
    "        \n",
    "        # Calculate v(T U {i})\n",
    "        idx_xs_incl = copy.copy(set_idx)\n",
    "        idx_xs_incl.append(i)\n",
    "        idx_xsc_incl = list(set(list(range(num_features))).difference(set(idx_xs_incl)))\n",
    "        acc_incl = get_acc_coef(y.reshape(-1, 1), x[:, idx_xs_incl], x[:, idx_xsc_incl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        # Calculate v(T)\n",
    "        idx_xsc_excl = list(range(num_features))\n",
    "        idx_xsc_excl.pop(i)\n",
    "        idx_xsc_excl = list(set(idx_xsc_excl).difference(set(set_idx)))\n",
    "        acc_excl = get_acc_coef(y.reshape(-1, 1), x[:, set_idx], x[:, idx_xsc_excl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        marginal = acc_incl - acc_excl\n",
    "        shapley = shapley + coef * marginal\n",
    "    return shapley\n",
    "\n",
    "\n",
    "def get_shapley_disc_i(y, x, protected_attr, i):\n",
    "    \"\"\"Returns Shapley coeffecient of ith feature in x.\"\"\"\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    lst_idx = list(range(num_features))\n",
    "    lst_idx.pop(i)\n",
    "    power_set = [x for x in powerset(lst_idx) if len(x) > 0]\n",
    "    \n",
    "    shapley = 0\n",
    "    for set_idx in power_set:\n",
    "        coef = math.factorial(len(set_idx)) * math.factorial(num_features - len(set_idx) - 1) / math.factorial(num_features)\n",
    "        \n",
    "        # Calculate v_D(T U {i})\n",
    "        idx_xs_incl = copy.copy(set_idx)\n",
    "        idx_xs_incl.append(i)\n",
    "        disc_incl = get_disc_coef(y.reshape(-1, 1), x[:, idx_xs_incl], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        # Calculate v_D(T)\n",
    "        disc_excl = get_disc_coef(y.reshape(-1, 1), x[:, set_idx], protected_attr.reshape(-1, 1))\n",
    "        \n",
    "        marginal = disc_incl - disc_excl\n",
    "        shapley = shapley + coef * marginal\n",
    "    return shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/29/z1b1v1g14xn82wyq4fkt1k100000gn/T/ipykernel_5132/430155173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshap_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0macc_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shapley_acc_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdisc_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shapley_disc_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/29/z1b1v1g14xn82wyq4fkt1k100000gn/T/ipykernel_5132/4085409440.py\u001b[0m in \u001b[0;36mget_shapley_acc_i\u001b[0;34m(y, x, protected_attr, i)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0midx_xs_incl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0midx_xsc_incl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_xs_incl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0macc_incl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_acc_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_xs_incl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_xsc_incl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Calculate v(T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/29/z1b1v1g14xn82wyq4fkt1k100000gn/T/ipykernel_5132/4085409440.py\u001b[0m in \u001b[0;36mget_acc_coef\u001b[0;34m(y, x_s, x_s_c, protected_attr)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_acc_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mconditional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_conditional_info_coef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/29/z1b1v1g14xn82wyq4fkt1k100000gn/T/ipykernel_5132/4085409440.py\u001b[0m in \u001b[0;36mget_conditional_info_coef\u001b[0;34m(left, right, conditional)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mp_r1_given_r3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_left_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_left_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconcat_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnum_right_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_right_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnum_right_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_right_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mp_r1_given_r3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate Shapley disc, acc coefs for each feature over training data\n",
    "shap_acc = []\n",
    "shap_disc = []\n",
    "for i in range(5):\n",
    "    acc_i = get_shapley_acc_i(y_train, x_train, race_train, i)\n",
    "    disc_i = get_shapley_disc_i(y_train, x_train, race_train, i)\n",
    "    \n",
    "    shap_acc.append(acc_i)\n",
    "    shap_disc.append(disc_i)\n",
    "\n",
    "# Build Shapley output\n",
    "feature_names = [\"Prior Count\", \"Gender\", \"Charge Degree\", \"Length of Stay\", \"Age (Categorical)\"]\n",
    "shapley_df = pd.DataFrame(list(zip(feature_names, shap_acc, shap_disc)),\n",
    "                          columns=[\"Feature\", \"Shapley (Accuracy)\", \"Shapley (Discrimination)\"])\n",
    "shapley_df = shapley_df.sort_values(by=[\"Shapley (Discrimination)\"], ascending=[False]).reset_index(0, True)\n",
    "shapley_df.to_csv(\"../output/compas-data-shapley-table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Shapley (Accuracy)</th>\n",
       "      <th>Shapley (Discrimination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prior Count</td>\n",
       "      <td>2.46E+00</td>\n",
       "      <td>7.17E+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1.37E+00</td>\n",
       "      <td>4.92E+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age (Categorical)</td>\n",
       "      <td>1.29E+00</td>\n",
       "      <td>4.03E+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>1.31E+00</td>\n",
       "      <td>3.68E+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>1.24E+00</td>\n",
       "      <td>3.07E+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Shapley (Accuracy)  Shapley (Discrimination)\n",
       "0        Prior Count            2.46E+00                  7.17E+06\n",
       "1             Gender            1.37E+00                  4.92E+06\n",
       "2  Age (Categorical)            1.29E+00                  4.03E+06\n",
       "3     Length of Stay            1.31E+00                  3.68E+06\n",
       "4      Charge Degree            1.24E+00                  3.07E+06"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2E' % x)\n",
    "shapley_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 'Prior Count' has the sharpest affect on both discrimination and accuracy, so eliminating it can prove problematic for a classifier. However, a feature such as 'Age (Categorical)' is relatively discriminatory but eliminating it would not seriously reduce accuracy from our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build an SVM model that predicts whether a user will or will not recidivate given the aforementioned features. We calculate accuracy as well as calibration, the difference between accuracy amongst the groups. Finally, we build submodels which eliminate each feature iteratively and calculate both metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "test_cal = []\n",
    "\n",
    "# Build model for overall data inclusive of all features\n",
    "svm = SVC(kernel=\"linear\").fit(x_train, y_train)\n",
    "idx_race_1, idx_race_0  = np.where(race_test == 1)[0], np.where(race_test == 0)[0]\n",
    "test_acc.append(svm.score(x_test, y_test))\n",
    "test_cal.append(svm.score(x_test[idx_race_1], y_test[idx_race_1]) - svm.score(x_test[idx_race_0], y_test[idx_race_0]))\n",
    "\n",
    "# Eliminate one feature at a time build model\n",
    "for id_feature in range(x_train.shape[1]):\n",
    "    idxs = list(range(x_train.shape[1]))\n",
    "    idxs.pop(id_feature)\n",
    "    x_train_mod = x_train[:, idxs]\n",
    "    x_test_mod = x_test[:, idxs]\n",
    "    \n",
    "    svm = SVC(kernel=\"linear\").fit(x_train_mod, y_train)\n",
    "    acc = svm.score(x_test_mod, y_test)\n",
    "    cal = svm.score(x_test_mod[idx_race_1], y_test[idx_race_1]) - svm.score(x_test_mod[idx_race_0], y_test[idx_race_0])\n",
    "    \n",
    "    test_acc.append(acc)\n",
    "    test_cal.append(cal)\n",
    "    \n",
    "\n",
    "index_names = [\"None\", \"Prior Count\", \"Gender\", \"Charge Degree\", \"Length of Stay\", \"Age (Categorical)\"]\n",
    "test_acc = [x * 100 for x in test_acc]\n",
    "test_cal = [x * 100 for x in test_cal]\n",
    "results = pd.DataFrame(list(zip(index_names, test_acc, test_cal)),\n",
    "                          columns=[\"Eliminating Feature\", \"Accuracy (%)\", \"Calibration (%)\"])\n",
    "results[\"Delta (%)\"] = 2.00 - results[\"Calibration (%)\"]\n",
    "results.to_csv(\"../output/compas-data-test-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eliminating Feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Calibration (1-0)</th>\n",
       "      <th>Delta (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>68.17</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prior Count</td>\n",
       "      <td>64.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>61.07</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charge Degree</td>\n",
       "      <td>67.81</td>\n",
       "      <td>3.58</td>\n",
       "      <td>-1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Stay</td>\n",
       "      <td>67.81</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age (Categorical)</td>\n",
       "      <td>66.39</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Eliminating Feature  Accuracy  Calibration (1-0)  Delta (%)\n",
       "0                None     68.17               2.00      -0.00\n",
       "1         Prior Count     64.02               0.76       1.24\n",
       "2              Gender     61.07              -0.06       2.06\n",
       "3       Charge Degree     67.81               3.58      -1.58\n",
       "4      Length of Stay     67.81               1.63       0.37\n",
       "5   Age (Categorical)     66.39               1.61       0.39"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating the results, we must compare against the baseline calibration score of 2%.\n",
    "\n",
    "Clearly, our results differ somewhat from our pretraining procedures. For example, we show that eliminating 'Prior Count' should result in the strongest drop in discrimation but the results suggest that actually eliminating 'Gender' yields the greatest benefit to discrimation. However, our FFS process showed that dropping 'Charge Degree' is unnecessary and the results prove that as removing it from the training set results in a significantly more discriminatory classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
