{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FairnessConstraints.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz6mX1djuyGe"
      },
      "source": [
        "# Maximize Fairness Under Accuraacy constraints - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gup6jQ35u6DY"
      },
      "source": [
        "## 1) Preprocess Bank marketing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xv1_tUoXICI"
      },
      "source": [
        "#Load data \n",
        "import pandas as pd \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "fp = \"drive/MyDrive/data/bank-full.csv\"\n",
        "bank_df = pd.read_csv(fp, delimiter=\";\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf9VkU8raM7B"
      },
      "source": [
        "\n",
        "def process_data(bank_df): \n",
        "  \n",
        "  y_actual = bank_df[\"y\"].apply(lambda x: 1 if x == \"yes\" else -1)\n",
        "  age = bank_df[\"age\"].apply(lambda x: 1 if 25<= x <= 60 else 0)\n",
        "  bank_df = bank_df.drop(columns = [\"age\", \"y\", \"day\", \"month\"])\n",
        "\n",
        "  #Have more than two categories - one hot encode\n",
        "  columns = ['job', 'marital', 'education','contact','poutcome']\n",
        "  for c in columns: \n",
        "    dummies = pd.get_dummies(bank_df[c])\n",
        "    bank_df = pd.merge(bank_df, dummies, left_index = True, right_index = True)\n",
        "    bank_df = bank_df.drop(columns = [c])\n",
        "\n",
        "  #Binary variables, apply 1/0 for yes/no\n",
        "  binary_vars = ['default', 'housing', 'loan']\n",
        "  for b in binary_vars: \n",
        "    bank_df[b] = bank_df[b].apply(lambda x: 1 if x ==\"yes\" else 0 )\n",
        "\n",
        "  bank_df, y_actual, age = shuffle(bank_df, y_actual, age, random_state=0)\n",
        "\n",
        "  return bank_df.to_numpy(), y_actual.to_numpy(), age.to_numpy()\n",
        "\n",
        "def accuracy(w, x, y):\n",
        "  \n",
        "  pred = np.dot(x, w.reshape(35,1))\n",
        "  pred_prob = 1/(1+ 2.718**(-pred))\n",
        "  \n",
        "  pred_prob[pred_prob>=0.5] = 1\n",
        "  pred_prob[pred_prob<0.5] = -1\n",
        "\n",
        "  matches = np.where(pred_prob==y_train.reshape(pred_prob.shape))\n",
        "\n",
        "  return (matches[0].shape[0]/pred_prob.shape[0]), pred_prob"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0sVx6oZaXFO"
      },
      "source": [
        "X, y, age = process_data(bank_df)\n",
        "\n",
        "#X,y, and age shuffled already, split into train and test tests\n",
        "train_index = int(len(X)*.80)\n",
        "x_train, y_train, age_train = X[:train_index], y[:train_index], age[:train_index]\n",
        "x_test, y_test, age_test = X[train_index:], y[train_index:], age[train_index:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4IEXDvMXyhO",
        "outputId": "80eb3847-2486-4995-c42c-e6eac2e490b5"
      },
      "source": [
        "#Get optimal coefficients by just training normal LR model \n",
        "clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
        "print(f\"Logistic Regression Accuracy: {clf.score(x_test, y_test)}\")\n",
        "\n",
        "coeff = clf.coef_\n",
        "intercept = clf.intercept_\n",
        "optimal_loss = log_loss(y_train, clf.predict_proba(x_train))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8973791883224593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj28XDFV6c3w"
      },
      "source": [
        "#Reshape arrays to calcualte dist from decision boundary \n",
        "ind = x_train.shape[0]\n",
        "lift = np.ones(ind).reshape(ind, 1)\n",
        "x_train = np.concatenate((x_train, lift), axis = 1)\n",
        "\n",
        "optimal_weights = np.concatenate((coeff, intercept.reshape(1,1)), axis = 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obRqt4CjqMqg"
      },
      "source": [
        "#Create Constraints for optimization problem \n",
        "#clf.predict_proba(x_train)\n",
        "def logisitc_loss(weights, X, y):\n",
        "\n",
        "  dp = np.dot(X, weights.reshape(35,1))\n",
        "  dp =dp.astype(np.float64)\n",
        "  pred_prob = 1/(1+ 2.718**(-dp))\n",
        "\n",
        "  pred_classes = np.concatenate((1-pred_prob, pred_prob), axis = 1)\n",
        "  loss = log_loss(y, pred_classes)\n",
        "\n",
        "  return loss "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdpsTHsUCC8Y"
      },
      "source": [
        "def constraint1(weights, x, y):\n",
        "  \n",
        "  upd_loss = logisitc_loss(weights, x, y)\n",
        "\n",
        "  return (1+gamma)*optimal_loss - upd_loss #Accuracy constraint function from paper "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nXHGI68DGgN"
      },
      "source": [
        "#Optmization function to minimize \n",
        "def opt_function(w, x, protected_var):\n",
        "  \n",
        "  dist_bound = np.dot(w, x_train.T)\n",
        "  protected_cov = (protected_var - np.mean(protected_var)) * dist_bound\n",
        "  \n",
        "  return float(abs(np.sum(protected_cov))) / float(x_train.shape[0])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nprlkbGyKQbv"
      },
      "source": [
        "#Determine p% rule ratio - number of protected in the positive class: not protected in positive class\n",
        "def p_rule(age_var, predicted_y):\n",
        "  \n",
        "  not_protected = np.where(age_var != 1)[0]\n",
        "  protected = np.where(age_var == 1)[0] \n",
        "\n",
        "  protected_preds = np.where(predicted_y[protected] == 1)\n",
        "  nonpro_preds = np.where(predicted_y[not_protected] == 1)\n",
        "\n",
        "  perc_ratio = (protected_preds[0].shape[0]/protected.shape[0])/(nonpro_preds[0].shape[0]/not_protected.shape[0])\n",
        "\n",
        "  return perc_ratio\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onDO_MQqkVeC",
        "outputId": "7db1b0aa-b00f-4bde-fe09-f47aa6ab60dc"
      },
      "source": [
        "#https://towardsdatascience.com/optimization-with-scipy-and-application-ideas-to-machine-learning-81d39c7938b8\n",
        "from scipy import optimize\n",
        "gamma = 0.5\n",
        "cons = {'type':'ineq', 'fun': constraint1, 'args': (x_train, y_train)}\n",
        "\n",
        "result = optimize.minimize(opt_function,\n",
        "                           x0=optimal_weights,\n",
        "                           args= (x_train,age_train),\n",
        "                           method='SLSQP',\n",
        "                           constraints=cons,\n",
        "                           options={'maxiter':10})\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in power\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in power\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in power\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in power\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpZb8nNcFHf5",
        "outputId": "52878443-e349-4958-f345-2e55510dab5f"
      },
      "source": [
        "result"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0.029138651963161573\n",
              "     jac: array([-4.52482840e-04,  2.42700321e+01, -1.35448407e-02, -4.90969815e-03,\n",
              "        1.54766212e+00, -2.73674491e-02,  4.97470845e-01,  1.30606962e-02,\n",
              "       -2.54969136e-03, -5.69617329e-03, -1.11719617e-03,  1.29369786e-04,\n",
              "       -6.12392649e-03,  1.72699948e-02, -8.18497268e-04, -2.09253910e-03,\n",
              "        6.33785198e-03, -4.80537978e-03, -7.10967695e-04,  1.77153386e-04,\n",
              "       -7.09632877e-04, -3.29249771e-03,  4.00213036e-03,  3.76235601e-03,\n",
              "       -1.46457413e-03, -4.81153652e-03,  2.51375418e-03,  1.56183960e-04,\n",
              "        6.63564773e-03, -6.79183216e-03, -1.02818478e-04,  8.27180455e-04,\n",
              "        4.38000355e-03, -5.10436622e-03,  0.00000000e+00])\n",
              " message: 'Iteration limit exceeded'\n",
              "    nfev: 77\n",
              "     nit: 2\n",
              "    njev: 2\n",
              "  status: 9\n",
              " success: False\n",
              "       x: array([-3.18810944e-02, -6.23799635e-04, -8.67269924e-01, -2.94533431e-01,\n",
              "        6.23096097e-03, -1.14287494e-01,  1.24018258e-03, -2.10365207e-03,\n",
              "       -5.80513178e-02, -3.39050346e-01, -6.00063028e-02, -5.31842995e-02,\n",
              "       -1.01595734e-01,  6.98120201e-02, -4.53907097e-02, -1.32665359e-01,\n",
              "        6.80211444e-02, -1.21674952e-01, -2.05145231e-02, -5.78768582e-03,\n",
              "       -1.67306931e-01, -4.99142358e-01, -1.33638776e-01, -2.57275628e-01,\n",
              "       -4.17253757e-01, -8.50495295e-02, -4.05091514e-02, -6.76896578e-02,\n",
              "       -2.10659766e-02, -7.11332431e-01, -2.25370382e-01, -5.09869372e-02,\n",
              "        4.09691056e-01, -9.33421802e-01, -8.00600395e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gujEWHagCyCU"
      },
      "source": [
        "val, pred_y = accuracy(result.x, x_train, y_train)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjMhgS97Odhd",
        "outputId": "b7972cf3-279e-44f6-9f93-bf92c174da72"
      },
      "source": [
        "val"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8734240212342402"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1_aikyiPFCm",
        "outputId": "8f176aa4-8ca3-4362-c9f7-58ab95242061"
      },
      "source": [
        "p_rule(age_train, pred_y)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1166947094337898"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc8V0XtMOggT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}